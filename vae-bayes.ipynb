{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#imports\nimport matplotlib.pyplot as plt\nimport scipy.io\nimport numpy as np\n!pip install torch-summary\nimport torchsummary\nimport torch\nimport torchvision \nimport torch.nn as nn\nimport torch.functional as f\nimport torch.optim as optim\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the data is here: https://cs.nyu.edu/~roweis/data.html\nimages=scipy.io.loadmat(\"/kaggle/input/frey-rawface/frey_rawface_k.mat\", squeeze_me=True, struct_as_record=False)\nimages=images[\"ff\"].T.reshape((-1, 28, 20))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(images[115])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(40)# so we generate the same random numbers\nn_pixels = 28 * 20#number of features\nX_train = images[:1800]#train_data\nX_val = images[1865:1965]#val_data\nX_train = X_train.astype('float32') / 255. #normalizing and making it a real number\nX_val = X_val.astype('float32') / 255.  #making it a float because most of ml algorithms require  data to be float \nX_train = X_train.reshape((len(X_train), n_pixels))#reshaping it => (1800, n_pixels) <==> (number of samples, number of features)\nX_val = X_val.reshape((len(X_val), n_pixels))\nX_train=torch.tensor(X_train)\nX_val=torch.tensor(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # here the preprocessing ends\n # and The Model construction starts!   \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_dim, intermediate_dim, latent_dim):\n        super(Encoder, self).__init__()\n        self.fc1 = nn.Linear(input_dim, intermediate_dim)#intermediate_dim extracts the imporatant features of our high dim image \n        self.fc2 = nn.Linear(intermediate_dim, latent_dim)\n        self.fc3 = nn.Linear(intermediate_dim, latent_dim)\n    \n    def forward(self, x):\n        h = torch.tanh(self.fc1(x))#I used tanh as the paper said C.2, we are encoding x in the latent space z\n        z_mean = self.fc2(h)# decoder part is when x is swapped with z (according to C.2 appendix)\n        z_log_var = self.fc3(h) \n        return z_mean, z_log_var\n\ninput_dim = n_pixels\nintermediate_dim = 256\nlatent_dim = 2\nencoder = Encoder(input_dim, intermediate_dim, latent_dim)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We need to sample z from the q_phi(z|x)\ndef sampling(z_mean, z_log_var):\n   \n    epsilon = torch.randn(100, latent_dim, dtype=torch.float32)#100=batch size (according to the paper it's the best)\n    epsilon *= torch.exp(.5 * z_log_var)#ensure that the standard deviation of the noise is not too large or too small\n    epsilon += z_mean\n    return epsilon\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.h1 = nn.Linear(latent_dim, intermediate_dim)\n        self.h2 = nn.Linear(intermediate_dim, n_pixels)\n\n    def forward(self, z):\n        x = torch.tanh(self.h1(z))#tanh like the paper (this is the decoded z)\n        x = torch.sigmoid(self.h2(x)) #this is the decoded x\n        return x\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now the VAE\nclass VAE(nn.Module):\n    def __init__(self,n_pixels, intermediate_dim, latent_dim):\n        super().__init__()\n        self.encoder = Encoder(n_pixels, intermediate_dim, latent_dim)\n        self.decoder = Decoder()\n        \n    def forward(self, x):\n        mean, log_var = self.encoder(x)\n        z = sampling(mean, log_var)\n        return self.decoder(z), mean, log_var\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae=VAE(input_dim, intermediate_dim, latent_dim)\ntorchsummary.summary(vae)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VAELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, x, x_decoded, z_mean, z_log_var):\n        loss = nn.MSELoss()(x, x_decoded)\n        kl_regu = -0.5 * torch.sum(1. + z_log_var - z_mean.pow(2) - z_log_var.exp(), dim=-1)\n        \n        return loss+ kl_regu#according to the formula in the paper\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(vae.parameters())\nloss_fn = VAELoss()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(100):\n    for i, t in enumerate(X_train):\n        # Forward pass\n        vae.train()\n        x_decoded, z_mean, z_log_var = vae(t)\n        loss = loss_fn(t, x_decoded[epoch], z_mean, z_log_var)\n        \n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    with torch.no_grad():\n        vae.eval()\n        val_loss = 0\n        for inputs in X_val:\n            outputs, z_mean_val, z_log_var_val = vae(inputs)\n            val_loss += loss_fn(inputs, outputs[epoch], z_mean_val, z_log_var_val).item()\n        avg_val_loss = val_loss / len(X_val)\n        print(\"Epoch {}: validation loss = {:.4f}\".format(epoch+1, avg_val_loss))    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nNotes:\nI used C.2 Gaussian MLP  for my Encoder and Decoder class\nThe paper is: https://arxiv.org/pdf/1312.6114.pdf\nThis is an implementation of the paper so basically it needs a hyperparameter tuning, I mostly followed the numbers that \nwere suggested by the authors.\n\nIf you want to improve the implementation(train on gpu,hyperparameter tuning,choice of loss function....) I would love to help.\n\nThank you for following up\n\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}